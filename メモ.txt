研究テーマ：
時系列情報のない集団データを用いた知識推定

関連研究：
Knowledge Tracing, Cognitive Diagnostic Model（認知診断モデル）, Educational concept map


対角成分が大きくなってしまった。
→Crossentropyを使っており、outputの確率が1を超えるとlossが正になり有利になるから積極的に1を超えてた。

対角成分を-3に固定して学習するといい感じの形になった！

叩き台としての近似は、2stepくらいなら上手くいくが、距離が長くなるとほとんど最初のワンステップのみしか学習してくれなくなった。

    # 正解数が多いほど損失が大きくなっている事に注意（修正すべきか？）
    loss = criterion(outputs, train_Y)


やりたいこと
2ルート作ってみる。違う分野だと想定する。

L2変えた時、-3も変更する必要あるのでは

2024.10.4
対角成分を-infにしてしまうと微妙な値が取れなくなってしまう可能性がある。
→値が1を超えないように調整してみる。ex. max(outputs, 1)

・検証方法
・全ての経路について求める方法
・

実験
下半分行列によるデータ生成　検証
経路分かってるデータに対して1ステップを当てれるか？　評価
時系列込みで学習したモデルにどのくらい迫れるか　比較
データサイズ、色々な行列A　検証
10パーとかデータ分ける？

構造
DINAモデルに依存関係を修正して測定

2024/11/19
近年の認知診断モデルの展開
参考になる

lilelyhoodで誤差を測定する。

遷移確率を計算するだけでなく状態確率も比較する必要がある。
→けどある状態から次にどの状態に遷移するかだけを知りたいのであれば、遷移確率だけでもいい？

11/21
次やること
機械学習を用いない予測確率分布と比較してみる
データ生成をDINAモデルをベースに行う

11/27
データ生成について
or形式(DINO)でデータ生成するなら、ノード同士の隣接行列作って解くというモデルを導入する方が良さそう。
今回のモデルを使う良さは、習得していないと解けないことを前提としたDINAモデルを前提しないとモデル選びの辻褄が合わない気がしてきた。
それぞれのノードに対して、たまたま正解する確率を仮定することでデータ生成する方が良いのでは？

11/28
疑問点：結局やってることCDMと同じでは？

12/2
検証データ入れなきゃ

12/3
3-PL model:


12/4
目標はKC(Knowledge concept)の関係性を抽出すること。
そこからできれば新たな問題に対しても対応できるようにしたい。

12/5
至急やるべきこととしては、データ生成の見直し。


12/9
CDMの規模感にデータ生成を合わせる。
CDM 2回分のテストデータを探してみる。

12/15
データのノイズが無い分比較手法がかなり高く評価されている。
データの生成方法
→DINAモデルをもう一度調べる。
自動生成

進んだら、guessingparaやslipなど入れて要素ごとの特性を入れるべき
今のままでは、要素1,2を習得した瞬間要素3の習得要件を満たしているというよくわからない状況。
足し算を習得したからといって掛け算ができるようになるわけではない。どちらかというと集合の全体を埋めるのを習得とした時に部分集合が埋まったとい感じ。
包含関係の違和感がここにある。1,1,0,0,0と,1,1,1,0,0だからと言って包含とは限らない。
問題４を解くのに問題3には不必要（オーバースペック）な要素も含まれているかも
そもそもcdmとは？同じアトリビュートであれば同じ問題とみなせる？
包含関係を解消する必要がない気がする。
たまたま３問目正解から4問目正解できるのはよくわからん。

論文読んで調べる必要あり

CDMで用いられる一般的なデータ？

12/17
やること
CDMで用いられるデータの調査
→サーベイ論文から始める

12/20
KT assistmentsからKC作れるか
FrcSubを使って実験

12/26
別に人工データの次元nで良くないか？

1/6
Assistmentsの前半後半で
FrcSubの一部の生徒の問題を前後半に分けて前半で学習し、後半を既存手法と勝負

1/8
Q行列がないデータセットを使っていいのか懸念していたが、そもそもあったところで依存関係があるかも分からないのでとりあえずKTのデータセットで分野を用いてやってみればいい。
分野の中でも問題によって難易度は違うだろというツッコミは来るかもしれないが。

1/10
西田教授
学習した順番に影響されるのではないか。
→そうだよな...
人為的なシステムでは、この疑念を晴らすことができない気がする。
理想的には、介入のない状態持つデータを使う方が良い気がする。例えば、スポーツ、病状とか？だけどそういうのも介入は入ってる（例：指導、薬）。

1/20
DINAに入れるテスト結果の形式は、[ユーザー数、問題数]であり、Q行列の形式は[問題数、スキル]であるから、理想的には学習段階においては全員同じ問題を解いていてほしい。

1/23
そもそも正解の方が多い。accuracyが0.5を割っているのも違和感。多分、全ての問題に対してguess, slipを考えて習得状態を推定しているのに急にテスト時だけ0.2に固定して予測するのがまずい。
もう少しちゃんとやり方を考える必要がある。


1/27
共通タグの集団テストを2回分作り、発展したスキルを当てられてるか評価。
それならDINAモデルでも問題ない。

1月テスト　[1, 0, 1, 1, 0, 1, 0]
2月テスト　[1, 0, 0, 1, 1, 1, 0] 下がっててもとりあえず論理和を取る
　　　　　 [1, 0, 1, 1, 1, 1, 0]

top_kが当たるか評価

2/3
例えば200-80に分けて、教師ありの200で学習させたモデルを上限として、80で今回のモデルがどこまで追従できるかを見る。統計手法は適用しにくいのでこれがベースラインになるかな。
案として、DINAモデルを用いる際、各状態で尤度が最も高いものを採用しているが、全体の期待値を取って状態推定する方が理にかなっているような気もした。
クロスバリデーションを行う。
また、人工データを用いて人数やスキル数を変えて実験もしてみる。


2/27
難易度ベースの手法に勝てない。
人工データでちゃんと勝てるか戻って検証する必要がある。

2/28
splitの方法に問題あり。何してんねん。
EdNet_mainとEdNet_main_newmodelから始める。
上限モデルのデータをシャッフルしたのと、分割率を0.7から0.8にした。

3/1
難易度ベースのモデルの遷移確率を評価する。多分提案手法より低くなるし、依存関係の復元が提案手法の良さであると主張する根拠になればいいなと思う。

3/2
グラフも難易度ベースでよくないか？破綻してる気がする。

3/7
上限モデルを全ステップで

1.人工データで勝てる
2.

難易度ベースに確率の推定では勝てる

上限モデルに勝ってもらう
実データで勝つ
実験設定を色々変える
次の1個の作り方。次に身につける1つ
勝てる設定探す



4/8
全てのパスで学習すると、学習データの偏り（序盤のスキル習得が非常に重視されてしまう）からあまり精度が上がらない。