# Knowledge Tracingの既存研究 
<!--
[1](#reference-1), <a id="reference-1"></a>...とすることで飛べるみたい
-->
<!-- [リンクテキスト](./a.md) -->

## 関連キーワード
Knowledge Tracing, Cognitive Diagnostic Model（認知診断モデル）, Knowledge Space, Knowledge Structure, Educational concept map, knowledge lattice, concept lattice, knowledge Hasse diagram


### 項目反応理論(IRT)
#### 2PLモデル
- 観測変数  
  - $y_{ij} \in \{0, 1\}$ （誤答、正答）

- モデル  
  $$
  P(y_{ij} = 1) = \text{logit}^{-1}(a_j (\theta_i - b_j)) = \frac{1}{1 + \exp(-a_j (\theta_i - b_j))}
  $$

- 解答者パラメータ  
  - $\theta_i$ : 達成度、潜在特性 (achievement, trait)  
  - $\theta_i \sim \text{Normal}(0, 1)$ （周辺最尤推定の場合）

- 項目パラメータ  
  - $a_j$ : 識別力 (discrimination)  
  - $b_j$ : 困難度 (difficulty)

## 手法
サーベイ論文[5]
* ベイズモデル

* 「Dynamic Bayesian Networks (DBN)  
  スキル間の階層的な関係を同時にモデル化できる。[6]  
  ↑本質的にやってること似てる？

* 部分観測可能マルコフ決定過程(POMDP)  
指数関数的に大きな状態空間が問題。

* the Performance Factors Analysis (PFA), LFA  
  ロジスティックモデル  
$p(θ) = σ\left(\sum_{i ∈ N} α_i S_i + \sum_{j ∈ KCs} (\beta_j + γ_j T_j) K_j \right)$  
ベイズに匹敵する性能。[7]

* Knowledge Tracing Machines  
  推薦システムで一般的に使用される行列分解技術を学生の学習パフォーマンス予測に応用。

* AdaBoost, Random Forest, linear
regression, logistic regression and a feed-forward neural network  
精度はいいが、正確な概念ラベリングを必要とする問題は解決できていない。

* Deep Knowledge Tracing  
RNNを組み込んだ。ここから系譜が出てきた。unlabelでもカテゴリ分けできるかもという主張。解釈可能性に問題。(1)観測された入力を再構成することができない、(2)時間ステップ間で予測された知識状態が一貫していない。[1]

* Dynamic Key-value memory network (DKVMN)  
  BKT: 各スキルを独立してモデル化し、複雑なスキル間の関係を捉えられない。DKT: LSTMベースで全体的な学習状態を要約するが、個々のスキルごとの理解度を特定できない。  
  DKTよりも解釈性を向上。KC表現行列(key)と知識状態表現行列(value)を明示的に保持。RNNをベースにしているため、 疎なデータを扱う際に汎化しないという問題。[4]



## アプローチ
### データの形状
元祖はスキルは忘れないと仮定
Guessing and Slipping estimatesや元々の能力、問題自体の難易度に拡張  
$\vec{h_t}=[q_t, a_t]$(演習タグ, 正誤)をワンホットエンコーディングとし、
$x_t \in [0,1]^{2M}$とする。スキルタグは入れておらず、大量のデータから生徒の回答元に依存関係を構築。学習段階では入力に答えまで入ってることに注意。出力がそれぞれの問題数の次元[1]

### データセット
サーベイ論文[5]
* 人工データ  
項目反応理論[2]より、   
$p(correct|\alpha, \beta)=c+\frac{1-c}{1+e^{\beta-\alpha}}$  
$\alpha$は概念スキル、$\beta$は問題の難易度、cはランダムな推測の確率(0.25)とする。回答するたびに概念スキルが向上するように設定。unlabelのデータにも対応できることを検証するために入力はインデックスと正誤だけを用いる。  
2000人の[1]
* Khan Academy Data
  69種類の演習タイプ、47,495人の学生、140万の演習[1]
* Benchmark Dataset[1]
  the Assistments 2009-2010 “skill builder”
  小学校の数学[1]

## この分野の貢献
* 出題すべき問題の選定
* 問題の依存関係の抽出  
$J_{ij}=\frac{y(j|i)}{\Sigma_ky(j|k)}$  
$y(j|k)$は最初に$i$を正解した時、$j$を正解する確率
これによって依存関係を抽出する。[1]

## 課題
Knowledge Tracingの課題
* 生徒の理解を二次元的に表現するのは非現実的
* 隠れ変数の意味と演習へのマッピングが曖昧
* 遷移をモデル化するために使用されるバイナリ応答データは、モデル化できる演習の種類に制限あり
* 生徒の知識状態の追跡ではなく解けそうかどうかのパターンの推定になってしまっている可能性あり。[9]

## 考察
問題(id)間の関係性（と時系列的な発展）を捉えられていることがBKTを上回る要因な気がする。[1]  

順序
* 学習において能力を測るためのスキル関係構造（と時間発展による習得構造）を反映した潜在的な知識状態$h$への変換モデルを構築する。  
* テストでは、生徒の演習（過去の数問）から知識状態$h$を推定。そこから未来の問題に対する正答率を出力する。

状況的には、全く未知のものを扱うことはなく、過去に出題された演習や知識概念(KC)を潜在的な知識状態に落とし込んでる。

<br>
<br>

## 認知診断モデル(CDM)
東大 岡田謙介先生
### DINAモデル
- 観測変数  
  - $y_{ij} \in \{0, 1\}$ （2値データ）

- 尤度  
  $$
  P(y_{ij} = 1) = (1 - s_j)^{\eta_{ij}} g_j^{1 - \eta_{ij}}
  $$  
  $$
  \eta_{ij} = \prod_{k=1}^{K} \alpha_{c_{ik}}^{q_{jk}} \quad \text{理想反応}
  $$

- 解答者パラメータ  
  - $c_i$ : アトリビュート習得パターン（潜在クラス）のうち1つへと解答者 $i$ を分類する際の、潜在クラス番号  
  - $c_i \sim \text{Categorical}(\pi), \pi \sim \text{Dirichlet}(1)$ （事前分布をおく場合）

- 項目パラメータ  
  - $s_j$ : slipパラメータ, $g_j$ : guessingパラメータ

DINAモデル（Deterministic Input, Noisy "And" gate model）の**slipパラメータ**と**guessingパラメータ**は、モデルの適合を通じてデータから推定されます。これらのパラメータの役割と一般的な値について以下に説明します。

---

### **1. slipパラメータ**
- **意味**:
  - Slip（スリップ）は、学習者が本来その問題を解くスキルを持っているにもかかわらず、間違えてしまう確率を表します。
  - 主にケアレスミスや一時的な失敗をモデル化します。

- **決定方法**:
  - 実データに基づいて、スキルを持つ学習者が間違える確率をモデルが推定します。
  - BayesianまたはEMアルゴリズムを使って最大尤度推定で得られます。

- **一般的な値**:
  - 教育データセットでは通常 **0.05～0.3** 程度が多いです。
    - 小さい値（0.05付近）：高信頼性のテストや簡単な問題。
    - 大きい値（0.3付近）：複雑なテストや学習者のスキルが不安定な場合。

---

### **2. guessingパラメータ**
- **意味**:
  - Guessing（ギャッシング）は、スキルを持っていない学習者が問題を正解する確率を表します。
  - 主に偶然当たる確率やテスト形式による影響をモデル化します（例：多肢選択問題での当てずっぽう）。

- **決定方法**:
  - 実データに基づいて、スキルを持たない学習者が正解する確率を推定します。
  - 同様に、最大尤度推定などで決まります。

- **一般的な値**:
  - 多肢選択式では、選択肢の数に依存します。
    - 例えば、選択肢が4つなら **0.25（1/4）** 付近が基本値。
  - 実際のデータでは、**0.1～0.3** の範囲で変動することが多いです。
    - 小さい値（0.1付近）：選択肢が多い、または偶然当たる可能性が低い場合。
    - 大きい値（0.3付近）：選択肢が少なく、運で正解しやすい場合。

---

### **まとめ**
- **slipパラメータ**: 本来正解できる学習者が間違える確率（一般的には **0.05～0.3**）。
- **guessingパラメータ**: 本来正解できない学習者が正解する確率（一般的には **0.1～0.3**、選択肢数に依存）。

これらは具体的なテスト設計や学習者集団に依存するため、事前に固定するのではなく、データに基づいて推定することが一般的です。

### Log-linear CDM
IRTと似た枠組みで分野関係を作れる。

### 段階反応モデル

### データセット
FreSub：分数の引き算。量もちょうどいい。
https://github.com/TerryPei/AGCDM/blob/main/dataset/FrcSub/q.txt
PISA：KC/Skillがねえや。
https://www.oecd.org/en/data/datasets/pisa-2018-database.html
TIMSSデータ？
TIMSS 2023 Longitudinal Study
Measuring Student Progress Over One Year  
https://timss2019.org/international-database/
TIMSSとは？
TIMSS は、国際的な数学および理科の学力調査で、世界中の生徒の学習成果を比較するために行われています。

対象: 小学校4年生および中学校2年生の生徒
目的: 数学および理科の教育成果とその背景要因を調査し、各国の教育システムを評価する
周期: 4年ごとに実施（1995年から開始）
調査内容:
数学および理科の学力テスト
学校や家庭環境、教育方法に関するアンケート（生徒、教師、保護者、学校管理者が回答）
TIMSSのポイント:

数学と理科の知識レベルやスキルを国際的に比較できる
教科内容（知識、応用力、問題解決力）を評価する
背景調査データにより、教育環境や指導方法の違いが学習成果に与える影響を分析できる

national educational panel study

教育分野における認知診断モデル（Cognitive Diagnostic Models, CDM）でよく使用されるデータセットは、通常、学生の試験成績や学習行動に基づいたデータです。以下に、CDM研究で頻繁に使われるデータセットの例を挙げます。

Rのパッケージ　CDM: Cognitive Diagnosis Modeling

##　データセット
The NeurIPS 2020 Education Challengeのデータセット

EduNetダウンロードしやすい　Contentsを参照してタグ付けする。
u321845は３日空いてる。よく見たらkBのファイルいっぱいあった！やったぜ

---

### **1. TIMSS (Trends in International Mathematics and Science Study)**
- **概要**: 国際的な数学および科学の学力評価データ。
- **特徴**: 学生の学力に関する多くの属性（スキルや知識の構成要素）を測定。
- **用途**: CDMでは、問題ごとのスキル診断や学力マップの作成に利用。

---

### **2. PISA (Programme for International Student Assessment)**
- **概要**: OECDが実施する15歳の学生を対象とした国際的な学力評価プログラム。
- **特徴**: 読解力、数学的リテラシー、科学的リテラシーを測定。
- **用途**: スキル分析や認知構造のモデル化に利用。

---

### **3. ASSISTments**
- **概要**: オンライン学習支援プラットフォームから収集されたデータセット。
- **特徴**: 問題ごとの正答・誤答データと、それに付随するメタデータ（問題のスキル属性など）。
- **用途**: 学習者のスキル推定、適応学習システムの構築。

---

### **4. NWEA MAP (Measures of Academic Progress)**
- **概要**: 学校や教師によって使用される適応型評価データ。
- **特徴**: 学力測定と、時間経過に伴う学習進度の追跡。
- **用途**: CDMを用いた学習進度やスキル構造の分析。

---

### **5. Fraction Subtraction Data**
- **概要**: 数学教育における分数の減算スキルを評価するデータ。
- **特徴**: 認知診断モデルで使いやすい形式で整備されており、スキルと問題の対応関係が明確。
- **用途**: CDMのベンチマークテストやアルゴリズム検証。

---

### **6. ECDL (E-Learning Content Data Logs)**
- **概要**: Eラーニングプラットフォームからの学習ログデータ。
- **特徴**: 問題解答データ、ログイン頻度、学習コンテンツ閲覧履歴などが含まれる。
- **用途**: 学習パターンの診断や適応学習システムの開発。

---

### **7. Simulated Q-matrix Data**
- **概要**: 理論的な研究で使用されるシミュレーションデータ。
- **特徴**: CDM用に設計されたQマトリックス（問題-スキル関係）に基づき、問題とスキル間の関係をモデル化。
- **用途**: アルゴリズム開発や手法比較の基盤。

---

### **8. National Assessment of Educational Progress (NAEP)**
- **概要**: 米国で実施される全国規模の学力評価。
- **特徴**: 詳細な学力指標と問題特性データ。
- **用途**: 教育政策の研究やスキル診断に利用。

---

これらのデータセットは、CDMの研究や適用において多様な観点から役立ちます。特に、スキル診断や学習支援システムの設計を行う際に用いられることが多いです。データセットによってアクセス条件が異なるため、使用前に必要な手続きやライセンス条件を確認してください。

<br>
<br>

## 方針
現状(12/4)時系情報が潰れた場合の知識推定で、状態遷移図を作ると、問題が完結してしまっている。  
方針としては、解けた問題セット([1, 1, 0,..., 1])から知識状態を推定(model1)し、その知識状態と問題状態を入力とし状態遷移図上を走らせる(model2)ことでEMアルゴリズムを作る。  
そのために、データ生成の段階で初めに能力を設定しておき、その上で状態遷移図上でデータを生成する。

鹿島先生  
時系列から時間情報を潰してデータ生成すればいいのでは？

2024/12/07  
新さん  
本来KTは、{問題,回答}のセットを入力として、潜在状態を更新することで、予測確率を出力している。  
今回時系列情報がない場合の予測として、KTに寄せた想定で考えられるのは、本来KTで300問の問題が時系列順で得られ、順次知識状態が更新されるのに対して、本研究では、3回の定期テストで100問ずつ出題され、次のテストの正解を当てろというようなもの。  
1step進めば、必ず正解というのは状況として良くわからない。そもそも構造自体も教育課程に大きく依存するのでは？

2024/12/07  
今やっているのは（問題というより）スキルの依存関係のグラフ構築。  
そこからある生徒に関して、前回構築した知識構造を元に、新たな問題（スキルは構造構築時のものでなければならない）に対する正答率を遷移確率なども考慮しながら予測する。  
CDMを踏まえつつの予測なので的確なものが作れるのでは？  
新さんの言ってた1stepの意味が良くわからないというのは、modelを通すときにノードでの停滞を加味していないから予測の時も適切ではない予測になりうるということなのかもしれない。  
明確に、CDMの依存関係を前提としてデータ生成をする。
![alt用テキスト](![alt text](<名称未設定のノート-1 (1).jpg>))

## 参考文献
1. Piech, C., J. Bassen, Jonathan Huang, S. Ganguli, M. Sahami, L. Guibas, and Jascha Narain Sohl-Dickstein. 2015. “Deep Knowledge Tracing.” Neural Information Processing Systems abs/1506.05908 (June). http://arxiv.org/abs/1506.05908.
2. Drasgow, Fritz, and Charles L. Hulin. 1990. “Item Response Theory.” In Handbook of Industrial and Organizational Psychology, Vol, edited by Marvin D. Dunnette, 1:577–636. Consulting Psychologists Press, xxvii.
3. Pu, Shi, and Lee Becker. 2022. “Self-Attention in Knowledge Tracing: Why It Works.” In Artificial Intelligence in Education, 731–36. Springer International Publishing.
4. Zhang, Jiani, Xingjian Shi, Irwin King, and Dit-Yan Yeung. 2016. “Dynamic Key-Value Memory Networks for Knowledge Tracing.” arXiv [Cs.AI]. arXiv. http://arxiv.org/abs/1611.08108.
5. Shen, Shuanghong, Qi Liu, Zhenya Huang, Yonghe Zheng, Minghao Yin, Minjuan Wang, and Enhong Chen. 2021. “A Survey of Knowledge Tracing: Models, Variants, and Applications.” arXiv [Cs.CY]. arXiv. http://arxiv.org/abs/2105.15106.
6. Käser, Tanja, Severin Klingler, Alexander G. Schwing, and Markus Gross. 01 Oct.-Dec 2017. “Dynamic Bayesian Networks for Student Modeling.” IEEE Transactions on Learning Technologies 10 (4): 450–62.
7. Cen, Hao, Kenneth Koedinger, and Brian Junker. 2006. “Learning Factors Analysis – A General Method for Cognitive Model Evaluation and Improvement.” In Intelligent Tutoring Systems, 164–75. Lecture Notes in Computer Science. Berlin, Heidelberg: Springer Berlin Heidelberg.
8. Thai-Nghe, Nguyen, Lucas Drumond, Tomáš Horváth, Artus Krohn-Grimberghe, Alexandros Nanopoulos, and Lars Schmidt-Thieme. 2012. “Factorization Techniques for Predicting Student Performance.” In Educational Recommender Systems and Technologies: Practices and Challenges, 129–53. IGI Global.
9. Yin, Yu, Le Dai, Zhenya Huang, Shuanghong Shen, Fei Wang, Qi Liu, Enhong Chen, and Xin Li. 2023. “Tracing Knowledge Instead of Patterns: Stable Knowledge Tracing with Diagnostic Transformer.” In Proceedings of the ACM Web Conference 2023, 855–64. WWW ’23. New York, NY, USA: Association for Computing Machinery.


![alt用テキスト](![alt text](/Users/nagairyousuke/Desktop/スクリーンショット 2024-12-19 15.06.31.png))
“Cognitive Diagnostic Models and How They Can Be Useful.” n.d. https://www.cambridgeassessment.org.uk/Images/701443-cognitive-diagnostic-models-and-how-they-can-be-useful.pdf.